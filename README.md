# An-Analysis-System-for-Online-Learners-behavior

### 신체 특징점 기반의 온라인 학습자 태도 분석  
https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11047736

한밭대학교 컴퓨터공학과 2021년 캡스톤디자인 팀 프로젝트 (김상민, 이택준, 이인석)


#### 학습자 상태 분석의 프로세스 <br/>
학습자들의 특징점을 검출하기 위해 Google의 Mediapipe를 사용하였다. Mediapipe를 이용하여 특징점을 검출하는 과정은 다음과 같다.  
1. Zoom 회의 프로그램으로부터 학습자들의 모습을 실시간으로 캡처해 프레 임단위로 이미지를 얻는다.  
2. 캡처한 이미지에서 사람을 인식하고 해당영역에서 얼굴과 신체 특징점을 검출한다.  
3. 검출한 특징점들을 이용하여 특징점간 거리 비율, 각도를 계산하고 계산된 값을 상태 분석 기준과 대조하여 학습자의 상태를 결정한다.<br/>

<br/>

#### 얼굴 특징점

얼굴의 특징점은 구글의 미디어 파이프를 이용하여 얼굴상의 468개의 점을 추출한 뒤 그중 중요한 특징점을 나타내는 42개의 점을 선별하였다. 선별한 42개의 특징점을 사용해 상태분석에 필요한 기준을 정립하였다. 기준을 정립하는 과정에서 웹캠 화면에 나타나는 사용자의 얼굴이 화면에서 차지하는 크기와 픽셀의 개수가 학습자의 환 경마다 달라지기 때문에 각각의 특징점을 활용한 비율과 각도를 기준으로 만들어 사용하여 다양한 환경에서 발생하는 오차를 최소화하도록 하였다. 이렇게 42개의 특징점을 기반으로 최종적으로 16가지의 얼굴 특징점을 계산했다.<br/>

<br/>

#### 신체 특징점

태도를 분석하기 위해서는 얼굴의 특징점 뿐만아니라 신체적 특징점도 고려해야 한다. 신체 특징점은 Mediapipe를 이용하여 총 33개의 특징점을 추출한 뒤 학 습자의 상태를 분석하는데 필요한 특징점 5개를 선별하였다. 선별한 특징점 중 양쪽 어깨의 값을 이용해 양쪽 어깨의 사이의 중점을 구하고 해당 값을 학습자의 상태를 분석하는데 사용하였다. 특징점 6개를 이용하여 특징점간 거리, 각도를 계산한 값과 특징점의 검출 유무를 학습자의 상태 정보를 분석하는데 이용했다.<br/>

<br/>

#### 상태 분석

학습자 상태 분석은 검출한 얼굴 특징점 데이터와 신체 특징점 데이터를 모두 이용하여 기준을 정하였다. 기준을 정립할 때 무표정을 집중하고 있는 표정이라고 가정하고 이 때 수치 값의 분포를 확인하기 위해 FER2013데이터 셋을 이용했다. FER2013 데이터셋은 얼굴 및 표정 인식을 위한 경진대회에서 많이 활용 되는 공개 데이터로 인물사진과 인물사진의 7가지 감정에 대한 정보가 담겨있다. 따라서 해당 사진을 입력으로 신체 특징점을 추출해서 각 7가지 감정에 대한 얼굴 특징점의 분포값을 추출해서 “집중”, “잠”, “지루함” 상태에 대한 기준값을 설정했다. 정립한 무표정 기준을 기초로 눈의 비율과 각도, 고개의 숙임 정도와 기 울어짐정도, 턱을 괴고 있는지 등의 데이터를 각각의 신체 데이터의 상태로 눈 감고있음, 고개숙임, 고개기울어짐, 턱 괴고 있음 등의 상태 데이터로 재가공, 이 상태 데이터를 종합하여 “자리에 없음”, “집중”, “잠”, “지루함”의 상태 분류가 가능하도록 하였다.

#### 분석 결과에 따른 피드백

위 과정에서 최종적으로 얻은 학습자의 상태에 따른 피드백을 zoom 사용중에 시각적으로 보여주기 위해 오버레이 방식을 사용하여 zoom 회의 창에 맞는 위치에 이모티콘으로 표시하였다. zoom회의의 실행 
